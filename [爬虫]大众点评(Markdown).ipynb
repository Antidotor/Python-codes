{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b557a1",
   "metadata": {},
   "source": [
    "```python\n",
    "# 加载库\n",
    "\n",
    "# 数据分析库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# 爬虫库\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import ast\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b845b3",
   "metadata": {},
   "source": [
    "```python\n",
    "# '商家名称' + '商家链接'\n",
    "def get_name_url(res_text):\n",
    "    \n",
    "    name_url = re.findall('title=\"(.+?)\" target=\"_blank\" href=\"(.+?)\"  >\\n',res_text)\n",
    "    \n",
    "    name = []\n",
    "    url = []\n",
    "    \n",
    "    for v in name_url:\n",
    "        name.append(v[0])\n",
    "        url.append(v[1])\n",
    "    \n",
    "    return name, url\n",
    "```\n",
    "\n",
    "```python\n",
    "# '标签' + '位置'\n",
    "def get_tag_loc(res_text):\n",
    "    \n",
    "    tag_temp = re.findall('<span class=\"tag\">.+</span></a>\\n        <em class=\"sep\">',res_text)\n",
    "    tag_temp = [v.replace('</a>\\n        <em class=\"sep\">','') for v in tag_temp]\n",
    "    loc_temp = re.findall('</em>\\n        .+(<span class=\"tag\">.+</span>)',res_text)\n",
    "    \n",
    "    tag = [[v.replace('<svgmtsi class=\"tagName\">','') for v in n] for n in [re.findall('>(.+?)<',v) for v in tag_temp]]\n",
    "    loc = [[v.replace('<svgmtsi class=\"tagName\">','') for v in n] for n in [re.findall('>(.+?)<',v) for v in loc_temp]]\n",
    "    \n",
    "    tag = [v[0] for v in tag]\n",
    "    loc = [v[0] for v in loc]\n",
    "    \n",
    "    return tag, loc\n",
    "```\n",
    "\n",
    "```python\n",
    "# '评论数量'\n",
    "def get_comment(res_text):\n",
    "    \n",
    "    comment_list = []\n",
    "    comment = re.findall('<b>.+\\n条评价',res_text)\n",
    "    \n",
    "    for a in comment:\n",
    "        r = [v.replace('<svgmtsi class=\"shopNum\">','') for v in re.findall('>(.+?)<',a)]\n",
    "        comment_list.append(r)\n",
    "    \n",
    "    comment_list = [v[0] for v in comment_list]\n",
    "    \n",
    "    return comment_list\n",
    "```\n",
    "\n",
    "```python\n",
    "# '人均消费'\n",
    "def get_per(res_text):\n",
    "    per_temp = re.findall('人均\\n            (<b>￥.+</b>)', res_text)\n",
    "    per = [[v.replace('<svgmtsi class=\"shopNum\">','').replace('￥','') for v in re.findall('>(.+?)<', n)] for n in per_temp]\n",
    "    per = [v[0] for v in per]\n",
    "    return per\n",
    "```\n",
    "\n",
    "```python\n",
    "# '评分'\n",
    "def get_score(res_text):\n",
    "    score = ast.literal_eval(res_text).get('fiveScore')\n",
    "    return score\n",
    "\n",
    "# '口味'\n",
    "def get_score_flavor(res_text):\n",
    "    score_flavor = json.loads(res_text).get('shopRefinedScoreValueList')[0]\n",
    "    return score_flavor\n",
    "\n",
    "# '环境'\n",
    "def get_score_env(res_text):\n",
    "    score_env = json.loads(res_text).get('shopRefinedScoreValueList')[1]\n",
    "    return score_env\n",
    "\n",
    "# '服务'\n",
    "def get_score_service(res_text):\n",
    "    score_service = json.loads(res_text).get('shopRefinedScoreValueList')[2]\n",
    "    return score_service\n",
    "```\n",
    "\n",
    "```python\n",
    "# '地址'\n",
    "def get_address(res_text):\n",
    "    tag = re.findall('<div class=\"expand-info address\" itemprop=\"street-address\">.+?</div>', res_text)[0]\n",
    "    address_temp = re.findall('>(.+?)<', tag)\n",
    "    address = [re.sub('<e class=\"address\">|<d class=\"num\">| ','',v) for v in address_temp if v != ' '][1]\n",
    "    return address\n",
    "```\n",
    "\n",
    "```python\n",
    "# '电话'\n",
    "def get_tel(res_text):\n",
    "    tag = re.findall('<p class=\"expand-info tel\">.+?</p>', res_text)[0]\n",
    "    address_temp = re.findall('>(.+?)<', tag)\n",
    "    address_temp_1 = [re.sub('<d class=\"num\">| ','',v) for v in address_temp if v != ' ']\n",
    "    address = [v.replace('&nbsp;',' ') for v in address_temp_1][1]\n",
    "    return address\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a07854",
   "metadata": {},
   "source": [
    "```python\n",
    "# 获取商家信息页面\n",
    "\n",
    "# 设置爬取内容\n",
    "res_text = []\n",
    "\n",
    "# 设置爬取页数\n",
    "page = 3\n",
    "\n",
    "# 开始爬取\n",
    "for i in range(page):\n",
    "    \n",
    "    # 设置当前页码\n",
    "    page_num = str(i+1)\n",
    "    \n",
    "    # 设置链接\n",
    "    url = 'https://www.dianping.com/shanghai/ch10/g508r5941p' + page_num\n",
    "    \n",
    "    # 设置 headers\n",
    "    # User_Agent 与 Cookie 替换为对应内容\n",
    "    User_Agent = 'User_Agent'\n",
    "    Cookie = 'Cookie'\n",
    "    headers = {\n",
    "        'User-Agent': User_Agent,\n",
    "        'Cookie': Cookie\n",
    "    }\n",
    "    \n",
    "    # 进行访问\n",
    "    res = requests.get(url, headers=headers)\n",
    "    \n",
    "    # 当访问报错时停留 5s 继续访问\n",
    "    while res.status_code != 200:\n",
    "        print('                  ', end='\\r')\n",
    "        print('请等一下', end='\\r')\n",
    "        time.sleep(5)\n",
    "        res = requests.get(url, headers=headers)\n",
    "    \n",
    "    # 存储页面内容\n",
    "    res_text.append(res.text)\n",
    "    \n",
    "    # 停留 5s\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # 打印进度\n",
    "    print(str(i+1)+'/'+str(page)+' 页爬取完成', end='\\r')\n",
    "```\n",
    "\n",
    "```python\n",
    "# 3/3 页爬取完成\n",
    "```\n",
    "\n",
    "```python\n",
    "# 初始化数据\n",
    "score_list = []\n",
    "score_list_flavor = []\n",
    "score_list_env = []\n",
    "score_list_service = []\n",
    "address_list = []\n",
    "tel_list = []\n",
    "df = pd.DataFrame()\n",
    "df_score = pd.DataFrame()\n",
    "```\n",
    "\n",
    "```python\n",
    "# ['商家名称', '商家链接', '标签', '位置', '评论数量', '人均消费']\n",
    "name_temp, _ = get_name_url(res_text[i])                         # 商家名称\n",
    "_, url_temp = get_name_url(res_text[i])                          # 商家链接\n",
    "tag_temp, _ = get_tag_loc(res_text[i])                           # 标签\n",
    "_, loc_temp = get_tag_loc(res_text[i])                           # 位置\n",
    "comment_temp = get_comment(res_text[i])                          # 评论数量\n",
    "per_temp = get_per(res_text[i])                                  # 人均消费\n",
    "```\n",
    "\n",
    "```python\n",
    "# 合并标签页数据\n",
    "df_columns = ['商家名称', '商家链接', '标签', '位置', '评论数量', '人均消费']\n",
    "df_temp = pd.DataFrame([name_temp, url_temp, tag_temp, loc_temp, comment_temp, per_temp], index = df_columns).T\n",
    "```\n",
    "\n",
    "```python\n",
    "# 合并数据\n",
    "df = pd.concat([df, df_temp], ignore_index = True)\n",
    "\n",
    "# 查看数据\n",
    "df.head()\n",
    "```\n",
    "\n",
    "```python\n",
    "# 获取店铺名称\n",
    "title = get_name_url(res_text[i])[0]\n",
    "\n",
    "# 获取店铺 shopid\n",
    "shopid = [v.split('/')[-1] for v in get_name_url(res_text[i])[1]]\n",
    "```\n",
    "\n",
    "```python\n",
    "# 爬取店铺信息\n",
    "for v in shopid:\n",
    "\n",
    "    # ['评分', '口味', '环境', '服务']\n",
    "\n",
    "    # 设置链接\n",
    "    url = 'https://www.dianping.com/ajax/json/shopDynamic/reviewAndStar'\n",
    "\n",
    "    # 设置 params\n",
    "    # 打开 F12 找到 'https://www.dianping.com/ajax/json/shopDynamic/reviewAndStar' 对应标签查找相应内容\n",
    "    # token 与 uuid 替换为对应内容\n",
    "    token = 'token'\n",
    "    uuid = 'uuid'\n",
    "    params = {\n",
    "        'shopId': v,\n",
    "        'cityId': '1',\n",
    "        'mainCategoryId': '34245',\n",
    "        '_token': token,\n",
    "        'uuid': uuid,\n",
    "        'platform': '1',\n",
    "        'partner': '150',\n",
    "        'optimusCode': '10',\n",
    "        'originUrl': 'https://www.dianping.com/shop/'+v\n",
    "    }\n",
    "\n",
    "    # 设置 headers\n",
    "    # User_Agent 与 Cookie 替换为对应内容\n",
    "    headers = {\n",
    "        'User-Agent': User_Agent,\n",
    "        'Cookie': Cookie\n",
    "    }\n",
    "\n",
    "    # 进行访问\n",
    "    res = requests.get(url, headers = headers, params = params)\n",
    "    while res.status_code != 200:\n",
    "        print('休息一下。')\n",
    "        time.sleep(5)\n",
    "        res = requests.get(url, headers = headers, params = params)\n",
    "\n",
    "    # 获取页面文本\n",
    "    res_text_score = res.text\n",
    "\n",
    "    # 获取店铺 ['评分']\n",
    "    score = get_score(res_text_score)\n",
    "\n",
    "    # 获取店铺 ['口味', '环境', '服务'] 评分\n",
    "    lst = ['flavor', 'env', 'service']\n",
    "    for l in lst:\n",
    "        exec('score_'+l+' = get_score_'+l+'(res_text_score)')\n",
    "\n",
    "    # 合并数据\n",
    "    score_list.append(score)\n",
    "    score_list_flavor.append(score_flavor)\n",
    "    score_list_env.append(score_env)\n",
    "    score_list_service.append(score_service)\n",
    "\n",
    "    # ['地址', '电话']\n",
    "\n",
    "    # 设置链接\n",
    "    url = 'https://www.dianping.com/shop/'+v\n",
    "\n",
    "    # 设置 headers\n",
    "    # User_Agent 与 Cookie 替换为对应内容\n",
    "    headers = {\n",
    "        'User-Agent': User_Agent,\n",
    "        'Cookie': Cookie\n",
    "    }\n",
    "\n",
    "    # 进行访问\n",
    "    res = requests.get(url, headers = headers)\n",
    "\n",
    "    # 获取店铺 ['地址']\n",
    "    address = get_address(res.text)\n",
    "\n",
    "    # 获取店铺 ['电话']\n",
    "    tel = get_tel(res.text)\n",
    "\n",
    "    # 合并数据\n",
    "    address_list.append(address)\n",
    "    tel_list.append(tel)\n",
    "\n",
    "    # 停留 5s\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 打印进度\n",
    "    print(str(i+1)+'/'+str(len(res_text))+' 页 '+str(shopid.index(v)+1)+'/'+str(len(shopid))+' 爬取完成', end='\\r')\n",
    "\n",
    "# 1/3 页 15/15 爬取完成\n",
    "```\n",
    "\n",
    "```python\n",
    "# 合并评分数据\n",
    "df_score_columns = ['评分', '口味', '环境', '服务', '地址', '电话']\n",
    "df_score_temp = pd.DataFrame([score_list, score_list_flavor, score_list_env, score_list_service, address_list, tel_list], index = df_score_columns).T\n",
    "df_score = pd.concat([df_score, df_score_temp], ignore_index=True)\n",
    "\n",
    "# 设置最终数据\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# 合并最终数据\n",
    "df_final_temp = pd.concat([df, df_score], axis=1)\n",
    "df_final = pd.concat([df_final, df_final_temp], ignore_index= True)\n",
    "\n",
    "# 导出最终数据\n",
    "df_final.to_excel('./dianping.xlsx', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f9022",
   "metadata": {},
   "source": [
    "```python\n",
    "# 全量爬取\n",
    "\n",
    "# 设置最终数据\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# 开始爬取\n",
    "for i in range(len(res_text)):\n",
    "\n",
    "    # 初始化数据\n",
    "    score_list = []\n",
    "    score_list_flavor = []\n",
    "    score_list_env = []\n",
    "    score_list_service = []\n",
    "    address_list = []\n",
    "    tel_list = []\n",
    "    df = pd.DataFrame()\n",
    "    df_score = pd.DataFrame()\n",
    "    \n",
    "    # ['商家名称', '商家链接', '标签', '位置', '评论数量', '人均消费']\n",
    "    \n",
    "    name_temp, _ = get_name_url(res_text[i])                         # 商家名称\n",
    "    _, url_temp = get_name_url(res_text[i])                          # 商家链接\n",
    "    tag_temp, _ = get_tag_loc(res_text[i])                           # 标签\n",
    "    _, loc_temp = get_tag_loc(res_text[i])                           # 位置\n",
    "    comment_temp = get_comment(res_text[i])                          # 评论数量\n",
    "    per_temp = get_per(res_text[i])                                  # 人均消费\n",
    "    \n",
    "    # 合并标签页数据\n",
    "    df_columns = ['商家名称', '商家链接', '标签', '位置', '评论数量', '人均消费']\n",
    "    df_temp = pd.DataFrame([name_temp, url_temp, tag_temp, loc_temp, comment_temp, per_temp], index = df_columns).T\n",
    "    \n",
    "    # 合并数据\n",
    "    df = pd.concat([df, df_temp], ignore_index = True)\n",
    "    \n",
    "    # ['评分', '口味', '环境', '服务', '地址', '电话']\n",
    "    \n",
    "    # 获取店铺名称\n",
    "    title = get_name_url(res_text[i])[0]\n",
    "    # 获取店铺 shopid\n",
    "    shopid = [v.split('/')[-1] for v in get_name_url(res_text[i])[1]]\n",
    "\n",
    "    # 爬取店铺信息\n",
    "    for v in shopid:\n",
    "\n",
    "        # ['评分', '口味', '环境', '服务']\n",
    "        \n",
    "        # 设置链接\n",
    "        url = 'https://www.dianping.com/ajax/json/shopDynamic/reviewAndStar'\n",
    "\n",
    "        # 设置 params\n",
    "        # 打开 F12 找到 'https://www.dianping.com/ajax/json/shopDynamic/reviewAndStar' 对应标签查找相应内容\n",
    "        # token 与 uuid 替换为对应内容\n",
    "        params = {\n",
    "            'shopId': v,\n",
    "            'cityId': '1',\n",
    "            'mainCategoryId': '34245',\n",
    "            '_token': token,\n",
    "            'uuid': uuid,\n",
    "            'platform': '1',\n",
    "            'partner': '150',\n",
    "            'optimusCode': '10',\n",
    "            'originUrl': 'https://www.dianping.com/shop/'+v\n",
    "        }\n",
    "\n",
    "        # 设置 headers\n",
    "        # User_Agent 与 Cookie 替换为对应内容\n",
    "        headers = {\n",
    "            'User-Agent': User_Agent,\n",
    "            'Cookie': Cookie\n",
    "        }\n",
    "\n",
    "        # 进行访问\n",
    "        res = requests.get(url, headers = headers, params = params)\n",
    "        while res.status_code != 200:\n",
    "            print('休息一下。')\n",
    "            time.sleep(5)\n",
    "            res = requests.get(url, headers = headers, params = params)\n",
    "\n",
    "        # 获取页面文本\n",
    "        res_text_score = res.text\n",
    "\n",
    "        # 获取店铺 ['评分']\n",
    "        score = get_score(res_text_score)\n",
    "\n",
    "        # 获取店铺 ['口味', '环境', '服务'] 评分\n",
    "        lst = ['flavor', 'env', 'service']\n",
    "        for l in lst:\n",
    "            exec('score_'+l+' = get_score_'+l+'(res_text_score)')\n",
    "\n",
    "        # 合并数据\n",
    "        score_list.append(score)\n",
    "        score_list_flavor.append(score_flavor)\n",
    "        score_list_env.append(score_env)\n",
    "        score_list_service.append(score_service)\n",
    "\n",
    "        # ['地址', '电话']\n",
    "        \n",
    "        # 设置链接\n",
    "        url = 'https://www.dianping.com/shop/'+v\n",
    "\n",
    "        # 设置 headers\n",
    "        # User_Agent 与 Cookie 替换为对应内容\n",
    "        headers = {\n",
    "            'User-Agent': User_Agent,\n",
    "            'Cookie': Cookie\n",
    "        }\n",
    "\n",
    "        # 进行访问\n",
    "        res = requests.get(url, headers = headers)\n",
    "\n",
    "        # 获取店铺 ['地址']\n",
    "        address = get_address(res.text)\n",
    "        \n",
    "        # 获取店铺 ['电话']\n",
    "        tel = get_tel(res.text)\n",
    "\n",
    "        # 合并数据\n",
    "        address_list.append(address)\n",
    "        tel_list.append(tel)\n",
    "\n",
    "        # 停留 5s\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # 打印进度\n",
    "        print(str(i+1)+'/'+str(len(res_text))+' 页 '+str(shopid.index(v)+1)+'/'+str(len(shopid))+' 爬取完成', end='\\r')\n",
    "    \n",
    "    # 合并评分数据\n",
    "    df_score_columns = ['评分', '口味', '环境', '服务', '地址', '电话']\n",
    "    df_score_temp = pd.DataFrame([score_list, \n",
    "                                  score_list_flavor, \n",
    "                                  score_list_env, \n",
    "                                  score_list_service, \n",
    "                                  address_list, \n",
    "                                  tel_list], \n",
    "                                 index = df_score_columns).T\n",
    "    df_score = pd.concat([df_score, df_score_temp], ignore_index=True)\n",
    "    \n",
    "    # 合并最终数据\n",
    "    df_final_temp = pd.concat([df, df_score], axis=1)\n",
    "    df_final = pd.concat([df_final, df_final_temp], ignore_index= True)\n",
    "    \n",
    "    # 停留 5s\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # 打印进度\n",
    "    print('                             ', end='\\r')\n",
    "    print(str(i+1)+'/'+str(len(res_text))+' 页爬取完成', end='\\r')\n",
    "```\n",
    "\n",
    "```python\n",
    "# 3/3 页爬取完成\n",
    "```\n",
    "\n",
    "```python\n",
    "# 导出最终数据\n",
    "df_final.to_excel('./大众点评爬取.xlsx', index=False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
